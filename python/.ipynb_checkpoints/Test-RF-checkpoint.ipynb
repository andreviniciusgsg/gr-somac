{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from RandomForest import RandomForest\n",
    "from SOMAC import SOMAC\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size = 455, Test set size = 330\n"
     ]
    }
   ],
   "source": [
    "filename = \"/home/andre/UFMG/SOMAC-ML/data/18092018/somac/RF-noweight/backlog_file.npy\"\n",
    "\n",
    "data = np.load(filename, encoding = \"latin1\").item()\n",
    "\n",
    "tkeys = np.array(list(data.keys()))\n",
    "\n",
    "train_keys = []\n",
    "test_keys = []\n",
    "\n",
    "for t in tkeys[:130]:\n",
    "    if np.random.rand() < 0.6:\n",
    "        train_keys.append(t)\n",
    "    else:\n",
    "        test_keys.append(t)\n",
    "        \n",
    "train = {}\n",
    "for i, t in zip(range(len(train_keys)), train_keys):\n",
    "    train[i] = data[t]\n",
    "train_file = \"./_tmp/train_file.npy\"\n",
    "np.save(train_file, train)\n",
    "\n",
    "test = {}\n",
    "for i, t in zip(range(len(test_keys)), test_keys):\n",
    "    test[i] = data[t]\n",
    "test_file = \"./_tmp/test_file.npy\"\n",
    "np.save(test_file, test)\n",
    "\n",
    "print(\"Train set size = {}, Test set size = {}\".format(len(train_keys), len(test_keys)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.load(test_file, encoding = \"latin1\").item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# somac = SOMAC(reg_csma = RandomForest(), reg_tdma = EsembleNNet())\n",
    "# EsembleNNet(n_new_estimators = 10, n_neurons = 3)\n",
    "somac = SOMAC(reg_csma = RandomForest(n_estimators = 100, max_depth = 5, max_features = \"log2\", n_new_estimators = 10),\n",
    "              reg_tdma = RandomForest(n_estimators = 100, max_depth = 5, max_features = \"log2\", n_new_estimators = 10))\n",
    "somac.train(train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prot: 0, y = 2.049999952316284\n",
      "y_hat_CSMA = [[9.0467406]], y_hat_TDMA = [[6.44023271]]\n",
      "Evaluation: v_csma = 8.7, v_tdma = 6.44\n",
      "Gain = 0.259387731004628\n",
      "---\n",
      "Prot: 0, y = 3.608620524406433\n",
      "y_hat_CSMA = [[6.67954402]], y_hat_TDMA = [[2.88778586]]\n",
      "Evaluation: v_csma = 6.19, v_tdma = 2.89\n",
      "Gain = 0.5336731585783611\n",
      "---\n",
      "Prot: 0, y = 19.16666668280959\n",
      "y_hat_CSMA = [[15.15001435]], y_hat_TDMA = [[8.87464526]]\n",
      "Evaluation: v_csma = 14.89, v_tdma = 8.87\n",
      "Gain = 0.4039170591656647\n",
      "---\n",
      "Prot: 0, y = 22.51666634902358\n",
      "y_hat_CSMA = [[14.25666728]], y_hat_TDMA = [[8.05464115]]\n",
      "Evaluation: v_csma = 14.42, v_tdma = 8.05\n",
      "Gain = 0.44146490370173913\n",
      "---\n",
      "Prot: 0, y = 25.016665633767843\n",
      "y_hat_CSMA = [[19.97036669]], y_hat_TDMA = [[12.13632204]]\n",
      "Evaluation: v_csma = 20.38, v_tdma = 12.14\n",
      "Gain = 0.4044636220029998\n",
      "---\n",
      "Prot: 0, y = 26.872988399118185\n",
      "y_hat_CSMA = [[16.62503007]], y_hat_TDMA = [[9.51973321]]\n",
      "Evaluation: v_csma = 17.53, v_tdma = 9.52\n",
      "Gain = 0.45680511541223623\n",
      "---\n",
      "Prot: 0, y = 26.166665967553854\n",
      "y_hat_CSMA = [[16.36888589]], y_hat_TDMA = [[8.50425684]]\n",
      "Evaluation: v_csma = 17.71, v_tdma = 8.5\n",
      "Gain = 0.5199178411158042\n",
      "---\n",
      "Prot: 0, y = 29.13160991668701\n",
      "y_hat_CSMA = [[27.88840671]], y_hat_TDMA = [[17.35526256]]\n",
      "Evaluation: v_csma = 29.23, v_tdma = 17.36\n",
      "Gain = 0.4062230189930693\n",
      "---\n",
      "Prot: 0, y = 29.918965257704258\n",
      "y_hat_CSMA = [[28.88726819]], y_hat_TDMA = [[19.34175789]]\n",
      "Evaluation: v_csma = 30.21, v_tdma = 19.34\n",
      "Gain = 0.359799357918109\n",
      "---\n",
      "Prot: 0, y = 27.679884925484657\n",
      "y_hat_CSMA = [[28.90055966]], y_hat_TDMA = [[19.57296748]]\n",
      "Evaluation: v_csma = 30.1, v_tdma = 19.57\n",
      "No. of new estimators = 8\n",
      "Gain = 0.34969305800121553\n",
      "---\n",
      "Prot: 0, y = 31.652299407869577\n",
      "y_hat_CSMA = [[28.89353574]], y_hat_TDMA = [[19.57296748]]\n",
      "Evaluation: v_csma = 29.94, v_tdma = 19.57\n",
      "Gain = 0.34629487698537015\n",
      "---\n",
      "Prot: 0, y = 31.183333594352007\n",
      "y_hat_CSMA = [[29.38771528]], y_hat_TDMA = [[19.33997034]]\n",
      "Evaluation: v_csma = 30.47, v_tdma = 19.34\n",
      "Gain = 0.36534374897087696\n",
      "---\n",
      "Prot: 0, y = 31.178735055029392\n",
      "y_hat_CSMA = [[28.60768467]], y_hat_TDMA = [[19.50792094]]\n",
      "Evaluation: v_csma = 29.77, v_tdma = 19.51\n",
      "Gain = 0.34465470264768994\n",
      "---\n",
      "Prot: 0, y = 27.366667483001947\n",
      "y_hat_CSMA = [[28.99489589]], y_hat_TDMA = [[23.43992894]]\n",
      "Evaluation: v_csma = 30.02, v_tdma = 23.44\n",
      "Gain = 0.2190649161792362\n",
      "---\n",
      "Prot: 0, y = 26.949999760836363\n",
      "y_hat_CSMA = [[28.89972462]], y_hat_TDMA = [[23.4708092]]\n",
      "Evaluation: v_csma = 29.77, v_tdma = 23.47\n",
      "Gain = 0.2116358968213955\n",
      "---\n",
      "Prot: 0, y = 28.30000071413815\n",
      "y_hat_CSMA = [[28.57985397]], y_hat_TDMA = [[20.86652857]]\n",
      "Evaluation: v_csma = 29.39, v_tdma = 20.87\n",
      "Gain = 0.2901111863780958\n",
      "---\n",
      "Prot: 0, y = 31.1844822447747\n",
      "y_hat_CSMA = [[28.96292149]], y_hat_TDMA = [[23.66509772]]\n",
      "Evaluation: v_csma = 29.85, v_tdma = 23.67\n",
      "Gain = 0.2071333889228487\n",
      "---\n",
      "Prot: 0, y = 30.71264409273863\n",
      "y_hat_CSMA = [[28.29335959]], y_hat_TDMA = [[23.82730837]]\n",
      "Evaluation: v_csma = 29.25, v_tdma = 23.83\n",
      "Gain = 0.18552168145902445\n",
      "---\n",
      "Prot: 0, y = 29.30229863896966\n",
      "y_hat_CSMA = [[28.88696572]], y_hat_TDMA = [[23.85043778]]\n",
      "Evaluation: v_csma = 29.82, v_tdma = 23.85\n",
      "Gain = 0.20021316387264457\n",
      "---\n",
      "Prot: 0, y = 0.4333335030823946\n",
      "y_hat_CSMA = [[8.19639486]], y_hat_TDMA = [[5.91660079]]\n",
      "Evaluation: v_csma = 8.7, v_tdma = 5.92\n",
      "No update. Forest is already full.\n",
      "Gain = 0.31958422270733333\n",
      "---\n",
      "Prot: 0, y = 0.6833329983055592\n",
      "y_hat_CSMA = [[4.92634091]], y_hat_TDMA = [[5.4009567]]\n",
      "Evaluation: v_csma = 5.19, v_tdma = 5.4\n",
      "Gain = 0.03935435120495472\n",
      "---\n",
      "Prot: 0, y = 0.30000000074505806\n",
      "y_hat_CSMA = [[4.99069168]], y_hat_TDMA = [[3.57858831]]\n",
      "Evaluation: v_csma = 5.01, v_tdma = 3.58\n",
      "Gain = 0.2850139878191489\n",
      "---\n",
      "Prot: 0, y = 0.33333249390125275\n",
      "y_hat_CSMA = [[7.97385394]], y_hat_TDMA = [[5.79721659]]\n",
      "Evaluation: v_csma = 7.61, v_tdma = 5.8\n",
      "Gain = 0.2377631271812546\n",
      "---\n",
      "Prot: 0, y = 0.2000000011175871\n",
      "y_hat_CSMA = [[7.41313204]], y_hat_TDMA = [[5.4574518]]\n",
      "Evaluation: v_csma = 6.7, v_tdma = 5.46\n",
      "Gain = 0.1857671888922125\n",
      "---\n",
      "Prot: 0, y = 0.43333299830555916\n",
      "y_hat_CSMA = [[3.17032566]], y_hat_TDMA = [[5.17615003]]\n",
      "Evaluation: v_csma = 2.36, v_tdma = 5.18\n",
      "Gain = 0.5443632364284189\n",
      "---\n",
      "Prot: 0, y = 0.29999999329447746\n",
      "y_hat_CSMA = [[7.41394293]], y_hat_TDMA = [[5.47188858]]\n",
      "Evaluation: v_csma = 6.29, v_tdma = 5.47\n",
      "Gain = 0.12964414391625906\n",
      "---\n",
      "Prot: 0, y = 0.0\n",
      "y_hat_CSMA = [[4.13200491]], y_hat_TDMA = [[5.53332553]]\n",
      "Evaluation: v_csma = 2.85, v_tdma = 5.53\n",
      "Gain = 0.4840771684245389\n",
      "---\n",
      "Prot: 1, y = 7.442528963088989\n",
      "y_hat_CSMA = [[17.23764015]], y_hat_TDMA = [[6.02417474]]\n",
      "Evaluation: v_csma = 15.96, v_tdma = 6.1\n",
      "Gain = 0.6181114578995532\n",
      "---\n",
      "Prot: 0, y = 0.5\n",
      "y_hat_CSMA = [[15.12287954]], y_hat_TDMA = [[5.30519085]]\n",
      "Evaluation: v_csma = 13.18, v_tdma = 5.38\n",
      "Gain = 0.5920500720720444\n",
      "---\n",
      "Prot: 0, y = 0.33333300054073334\n",
      "y_hat_CSMA = [[17.92653482]], y_hat_TDMA = [[11.04530762]]\n",
      "Evaluation: v_csma = 15.2, v_tdma = 11.12\n",
      "Gain = 0.268649136806535\n",
      "---\n",
      "Prot: 1, y = 13.112069487571716\n",
      "y_hat_CSMA = [[26.83308064]], y_hat_TDMA = [[18.74969191]]\n",
      "Evaluation: v_csma = 24.11, v_tdma = 18.54\n",
      "Gain = 0.23110071615242114\n",
      "---\n",
      "Prot: 1, y = 14.566667437553406\n",
      "y_hat_CSMA = [[26.62415318]], y_hat_TDMA = [[18.80749943]]\n",
      "Evaluation: v_csma = 23.9, v_tdma = 18.39\n",
      "Gain = 0.23038367108432173\n",
      "---\n",
      "Prot: 1, y = 15.847700953483582\n",
      "y_hat_CSMA = [[26.423023]], y_hat_TDMA = [[18.70808848]]\n",
      "Evaluation: v_csma = 23.7, v_tdma = 18.17\n",
      "Gain = 0.23320465143466662\n",
      "---\n",
      "Prot: 1, y = 15.840230584144592\n",
      "y_hat_CSMA = [[23.96077009]], y_hat_TDMA = [[18.69889632]]\n",
      "Evaluation: v_csma = 21.23, v_tdma = 18.04\n",
      "Gain = 0.15018514903006355\n",
      "---\n",
      "Prot: 1, y = 18.92241358757019\n",
      "y_hat_CSMA = [[28.76093995]], y_hat_TDMA = [[19.23598645]]\n",
      "Evaluation: v_csma = 26.03, v_tdma = 18.6\n",
      "Gain = 0.2855904464123797\n",
      "---\n",
      "Prot: 1, y = 21.32356321811676\n",
      "y_hat_CSMA = [[23.32494232]], y_hat_TDMA = [[16.84891217]]\n",
      "Evaluation: v_csma = 20.6, v_tdma = 16.47\n",
      "Gain = 0.20053168418067033\n",
      "---\n",
      "Prot: 1, y = 20.87643700838089\n",
      "y_hat_CSMA = [[27.54224725]], y_hat_TDMA = [[21.46151381]]\n",
      "Evaluation: v_csma = 24.82, v_tdma = 21.07\n",
      "Gain = 0.15093245295484325\n",
      "---\n",
      "Prot: 1, y = 21.707471132278442\n",
      "y_hat_CSMA = [[27.83230144]], y_hat_TDMA = [[21.21855271]]\n",
      "Evaluation: v_csma = 25.11, v_tdma = 20.87\n",
      "Gain = 0.16866605305967555\n",
      "---\n",
      "Prot: 1, y = 21.25517249107361\n",
      "y_hat_CSMA = [[27.89710686]], y_hat_TDMA = [[21.05979339]]\n",
      "Evaluation: v_csma = 25.17, v_tdma = 20.74\n",
      "No. of new estimators = 10\n",
      "Gain = 0.17603526461536068\n",
      "---\n",
      "Prot: 1, y = 24.25919610261917\n",
      "y_hat_CSMA = [[28.33142573]], y_hat_TDMA = [[23.80512603]]\n",
      "Evaluation: v_csma = 25.6, v_tdma = 23.58\n",
      "Gain = 0.07916449252720503\n",
      "---\n",
      "Prot: 1, y = 25.039655540138483\n",
      "y_hat_CSMA = [[27.98416453]], y_hat_TDMA = [[23.78766921]]\n",
      "Evaluation: v_csma = 25.26, v_tdma = 23.63\n",
      "Gain = 0.06426602662277914\n",
      "---\n",
      "Prot: 1, y = 25.452299647033215\n",
      "y_hat_CSMA = [[29.10974764]], y_hat_TDMA = [[23.8481151]]\n",
      "Evaluation: v_csma = 26.38, v_tdma = 23.78\n",
      "Gain = 0.09856524974864705\n",
      "---\n",
      "Prot: 1, y = 24.818964809179306\n",
      "y_hat_CSMA = [[28.03556612]], y_hat_TDMA = [[23.96819709]]\n",
      "Evaluation: v_csma = 25.31, v_tdma = 23.95\n",
      "Gain = 0.05374999064353816\n",
      "---\n",
      "Prot: 1, y = 0.18333350494503975\n",
      "y_hat_CSMA = [[5.05670729]], y_hat_TDMA = [[2.30160107]]\n",
      "Evaluation: v_csma = 2.33, v_tdma = 2.18\n",
      "Gain = 0.06566885093795345\n",
      "---\n",
      "Prot: 1, y = 0.33333350718021393\n",
      "y_hat_CSMA = [[4.72449598]], y_hat_TDMA = [[1.63521342]]\n",
      "Evaluation: v_csma = 2.0, v_tdma = 1.45\n",
      "Gain = 0.27334593743125485\n",
      "---\n",
      "Prot: 1, y = 0.21666650474071503\n",
      "y_hat_CSMA = [[4.98995862]], y_hat_TDMA = [[1.55855621]]\n",
      "Evaluation: v_csma = 2.26, v_tdma = 1.32\n",
      "Gain = 0.4180501245360449\n",
      "---\n",
      "Prot: 1, y = 0.18333350121974945\n",
      "y_hat_CSMA = [[5.05670729]], y_hat_TDMA = [[1.61265888]]\n",
      "Evaluation: v_csma = 2.33, v_tdma = 1.31\n",
      "Gain = 0.4369911696983362\n",
      "---\n",
      "Prot: 1, y = 0.11666649952530861\n",
      "y_hat_CSMA = [[5.05670729]], y_hat_TDMA = [[1.51098819]]\n",
      "Evaluation: v_csma = 2.33, v_tdma = 1.16\n",
      "Gain = 0.5040958179187492\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.98995862]], y_hat_TDMA = [[1.39311614]]\n",
      "Evaluation: v_csma = 2.26, v_tdma = 0.99\n",
      "No. of new estimators = 10\n",
      "Gain = 0.5644775322930705\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.99719817]], y_hat_TDMA = [[0.12374963]]\n",
      "Evaluation: v_csma = 2.27, v_tdma = -0.17\n",
      "Gain = 1.0735555601441118\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[5.08587702]], y_hat_TDMA = [[0.12302358]]\n",
      "Evaluation: v_csma = 2.36, v_tdma = -0.16\n",
      "Gain = 1.0675432764466657\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.98995862]], y_hat_TDMA = [[0.1216482]]\n",
      "Evaluation: v_csma = 2.26, v_tdma = -0.15\n",
      "Gain = 1.0674631903556937\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.68545326]], y_hat_TDMA = [[0.1213275]]\n",
      "Evaluation: v_csma = 1.96, v_tdma = -0.15\n",
      "Gain = 1.0742102253239176\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.72244052]], y_hat_TDMA = [[0.13767109]]\n",
      "Evaluation: v_csma = 2.0, v_tdma = -0.12\n",
      "Gain = 1.061412220530033\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[5.05670729]], y_hat_TDMA = [[0.12901327]]\n",
      "Evaluation: v_csma = 2.33, v_tdma = -0.12\n",
      "Gain = 1.0535013033986873\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.98995862]], y_hat_TDMA = [[0.12156666]]\n",
      "Evaluation: v_csma = 2.26, v_tdma = -0.13\n",
      "Gain = 1.055451436383508\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[5.05670729]], y_hat_TDMA = [[0.12348014]]\n",
      "Evaluation: v_csma = 2.33, v_tdma = -0.12\n",
      "Gain = 1.0503893342041064\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.98995862]], y_hat_TDMA = [[0.28368115]]\n",
      "Evaluation: v_csma = 2.26, v_tdma = 0.04\n",
      "Gain = 0.9820302026837076\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.98995862]], y_hat_TDMA = [[0.12776793]]\n",
      "Evaluation: v_csma = 2.26, v_tdma = -0.11\n",
      "No. of new estimators = 5\n",
      "Gain = 1.0483803150460362\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[5.05670729]], y_hat_TDMA = [[0.02087419]]\n",
      "Evaluation: v_csma = 2.33, v_tdma = -0.15\n",
      "Gain = 1.0642624506204308\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.98995862]], y_hat_TDMA = [[0.02353286]]\n",
      "Evaluation: v_csma = 2.26, v_tdma = -0.14\n",
      "Gain = 1.0617339153077108\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[5.08587702]], y_hat_TDMA = [[0.23380927]]\n",
      "Evaluation: v_csma = 2.36, v_tdma = 0.07\n",
      "Gain = 0.9715788319966384\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.68545326]], y_hat_TDMA = [[0.01901286]]\n",
      "Evaluation: v_csma = 1.96, v_tdma = -0.14\n",
      "Gain = 1.0716697005440692\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.98995862]], y_hat_TDMA = [[0.01925203]]\n",
      "Evaluation: v_csma = 2.26, v_tdma = -0.13\n",
      "Gain = 1.058824283907919\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.81762586]], y_hat_TDMA = [[0.01918409]]\n",
      "Evaluation: v_csma = 2.09, v_tdma = -0.13\n",
      "Gain = 1.0605203395610927\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.98995862]], y_hat_TDMA = [[0.01933357]]\n",
      "Evaluation: v_csma = 2.26, v_tdma = -0.12\n",
      "Gain = 1.0530532604846703\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[5.05670729]], y_hat_TDMA = [[0.01828749]]\n",
      "Evaluation: v_csma = 2.33, v_tdma = -0.12\n",
      "Gain = 1.0493831524073831\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[5.05670729]], y_hat_TDMA = [[0.01828749]]\n",
      "Evaluation: v_csma = 2.33, v_tdma = -0.11\n",
      "Gain = 1.0469139947870139\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[5.05670729]], y_hat_TDMA = [[0.01983941]]\n",
      "Evaluation: v_csma = 2.33, v_tdma = -0.1\n",
      "No. of new estimators = 1\n",
      "Gain = 1.0439354716763651\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[5.05670729]], y_hat_TDMA = [[0.02285301]]\n",
      "Evaluation: v_csma = 2.33, v_tdma = -0.07\n",
      "Gain = 1.0282514948414796\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.72244052]], y_hat_TDMA = [[0.06868172]]\n",
      "Evaluation: v_csma = 2.0, v_tdma = -0.02\n",
      "Gain = 1.009516902353668\n",
      "---\n",
      "Prot: 1, y = 0.01666649989783764\n",
      "y_hat_CSMA = [[4.96152194]], y_hat_TDMA = [[0.07461081]]\n",
      "Evaluation: v_csma = 2.23, v_tdma = -0.01\n",
      "Gain = 1.0051801350505523\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.96152194]], y_hat_TDMA = [[0.06794702]]\n",
      "Evaluation: v_csma = 2.23, v_tdma = -0.02\n",
      "Gain = 1.0077541509512369\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[5.00352688]], y_hat_TDMA = [[0.02189262]]\n",
      "Evaluation: v_csma = 2.28, v_tdma = -0.06\n",
      "Gain = 1.0264487163225813\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.96152194]], y_hat_TDMA = [[0.02021023]]\n",
      "Evaluation: v_csma = 2.23, v_tdma = -0.06\n",
      "Gain = 1.0263138466781234\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.59026791]], y_hat_TDMA = [[0.06867239]]\n",
      "Evaluation: v_csma = 1.86, v_tdma = -0.01\n",
      "Gain = 1.0052707648064807\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.98995862]], y_hat_TDMA = [[0.01915679]]\n",
      "Evaluation: v_csma = 2.26, v_tdma = -0.06\n",
      "Gain = 1.0249092668765785\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.98995862]], y_hat_TDMA = [[0.01895138]]\n",
      "Evaluation: v_csma = 2.26, v_tdma = -0.05\n",
      "Gain = 1.0237500341009043\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.59026791]], y_hat_TDMA = [[0.01946933]]\n",
      "Evaluation: v_csma = 1.86, v_tdma = -0.05\n",
      "No. of new estimators = 10\n",
      "Gain = 1.027138232741659\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.68545326]], y_hat_TDMA = [[0.00208697]]\n",
      "Evaluation: v_csma = 1.96, v_tdma = -0.05\n",
      "Gain = 1.0244928276144094\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.96152194]], y_hat_TDMA = [[0.00241805]]\n",
      "Evaluation: v_csma = 2.23, v_tdma = -0.05\n",
      "Gain = 1.0202527784225652\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.96152194]], y_hat_TDMA = [[0.00623207]]\n",
      "Evaluation: v_csma = 2.23, v_tdma = -0.04\n",
      "Gain = 1.0176186571945822\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[5.05670729]], y_hat_TDMA = [[0.00206716]]\n",
      "Evaluation: v_csma = 2.33, v_tdma = -0.04\n",
      "Gain = 1.0177522009527267\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.82942851]], y_hat_TDMA = [[0.00263856]]\n",
      "Evaluation: v_csma = 2.1, v_tdma = -0.04\n",
      "Gain = 1.0184294746487124\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.99719817]], y_hat_TDMA = [[0.00210682]]\n",
      "Evaluation: v_csma = 2.27, v_tdma = -0.04\n",
      "Gain = 1.0164366801796885\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.68545326]], y_hat_TDMA = [[0.00192507]]\n",
      "Evaluation: v_csma = 1.96, v_tdma = -0.04\n",
      "Gain = 1.0181885036006921\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[5.05670729]], y_hat_TDMA = [[0.00190525]]\n",
      "Evaluation: v_csma = 2.33, v_tdma = -0.03\n",
      "Gain = 1.0145336835280272\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.68823104]], y_hat_TDMA = [[0.00193439]]\n",
      "Evaluation: v_csma = 1.96, v_tdma = -0.03\n",
      "Gain = 1.016386879609727\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[5.05670729]], y_hat_TDMA = [[0.00349971]]\n",
      "Evaluation: v_csma = 2.33, v_tdma = -0.03\n",
      "No update. Forest is already full.\n",
      "Gain = 1.0124670738625023\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[5.05670729]], y_hat_TDMA = [[0.03109668]]\n",
      "Evaluation: v_csma = 2.33, v_tdma = -0.0\n",
      "Gain = 1.0005905615153137\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.59304569]], y_hat_TDMA = [[0.00235791]]\n",
      "Evaluation: v_csma = 1.87, v_tdma = -0.03\n",
      "Gain = 1.0153308943461021\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[5.05670729]], y_hat_TDMA = [[0.00343345]]\n",
      "Evaluation: v_csma = 2.33, v_tdma = -0.03\n",
      "Gain = 1.0112272231608999\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[5.05670729]], y_hat_TDMA = [[0.00196734]]\n",
      "Evaluation: v_csma = 2.33, v_tdma = -0.03\n",
      "Gain = 1.0112636924848482\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[5.05670729]], y_hat_TDMA = [[0.00359535]]\n",
      "Evaluation: v_csma = 2.33, v_tdma = -0.02\n",
      "Gain = 1.0100366578367381\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.90834153]], y_hat_TDMA = [[0.0058103]]\n",
      "Evaluation: v_csma = 2.18, v_tdma = -0.02\n",
      "Gain = 1.0092187159418655\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.98995862]], y_hat_TDMA = [[0.00216424]]\n",
      "Evaluation: v_csma = 2.26, v_tdma = -0.02\n",
      "Gain = 1.0099725243398527\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.98995862]], y_hat_TDMA = [[0.00208697]]\n",
      "Evaluation: v_csma = 2.26, v_tdma = -0.02\n",
      "Gain = 1.0095063328132716\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[5.00352688]], y_hat_TDMA = [[0.00532528]]\n",
      "Evaluation: v_csma = 2.28, v_tdma = -0.02\n",
      "Gain = 1.0076258698174372\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[5.05670729]], y_hat_TDMA = [[0.00343345]]\n",
      "Evaluation: v_csma = 2.33, v_tdma = -0.02\n",
      "No. of new estimators = 1\n",
      "Gain = 1.0078506336526913\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[5.05670729]], y_hat_TDMA = [[0.00357679]]\n",
      "Evaluation: v_csma = 2.33, v_tdma = -0.01\n",
      "Gain = 1.0052246717957705\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.90201283]], y_hat_TDMA = [[0.00255289]]\n",
      "Evaluation: v_csma = 2.18, v_tdma = -0.01\n",
      "Gain = 1.0057636564676589\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[5.05670729]], y_hat_TDMA = [[0.0017868]]\n",
      "Evaluation: v_csma = 2.33, v_tdma = -0.01\n",
      "Gain = 1.0054242901188697\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[5.05670729]], y_hat_TDMA = [[0.0018489]]\n",
      "Evaluation: v_csma = 2.33, v_tdma = -0.01\n",
      "Gain = 1.0051277567062715\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[5.08587702]], y_hat_TDMA = [[0.00339119]]\n",
      "Evaluation: v_csma = 2.36, v_tdma = -0.01\n",
      "Gain = 1.0041900078999064\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[5.05670729]], y_hat_TDMA = [[0.00592583]]\n",
      "Evaluation: v_csma = 2.33, v_tdma = -0.01\n",
      "Gain = 1.0029968041877144\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[5.05670729]], y_hat_TDMA = [[0.00350063]]\n",
      "Evaluation: v_csma = 2.33, v_tdma = -0.01\n",
      "Gain = 1.0038358812089057\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.68823104]], y_hat_TDMA = [[0.00181594]]\n",
      "Evaluation: v_csma = 1.96, v_tdma = -0.01\n",
      "Gain = 1.0051447451566458\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.98995862]], y_hat_TDMA = [[0.00220769]]\n",
      "Evaluation: v_csma = 2.26, v_tdma = -0.01\n",
      "Gain = 1.0040714005699465\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.96152194]], y_hat_TDMA = [[0.00229961]]\n",
      "Evaluation: v_csma = 2.23, v_tdma = -0.01\n",
      "No update. Forest is already full.\n",
      "Gain = 1.0038779760412084\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[5.05670729]], y_hat_TDMA = [[0.00333872]]\n",
      "Evaluation: v_csma = 2.33, v_tdma = -0.01\n",
      "Gain = 1.0031098398327536\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[5.00352688]], y_hat_TDMA = [[0.00534095]]\n",
      "Evaluation: v_csma = 2.28, v_tdma = -0.0\n",
      "Gain = 1.0021878437550005\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.81762586]], y_hat_TDMA = [[0.00198214]]\n",
      "Evaluation: v_csma = 2.09, v_tdma = -0.01\n",
      "Gain = 1.0037895054825818\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.84183346]], y_hat_TDMA = [[0.00190704]]\n",
      "Evaluation: v_csma = 2.11, v_tdma = -0.01\n",
      "Gain = 1.0035925576528124\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[5.05670729]], y_hat_TDMA = [[0.00332679]]\n",
      "Evaluation: v_csma = 2.33, v_tdma = -0.01\n",
      "Gain = 1.0025192263747682\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.95819632]], y_hat_TDMA = [[0.00272773]]\n",
      "Evaluation: v_csma = 2.23, v_tdma = -0.01\n",
      "Gain = 1.0027539914845494\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[5.0889559]], y_hat_TDMA = [[0.00520683]]\n",
      "Evaluation: v_csma = 2.36, v_tdma = -0.0\n",
      "Gain = 1.0014743617943715\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.98995862]], y_hat_TDMA = [[0.00220769]]\n",
      "Evaluation: v_csma = 2.26, v_tdma = -0.01\n",
      "Gain = 1.0027209387140585\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[5.05670729]], y_hat_TDMA = [[0.0065729]]\n",
      "Evaluation: v_csma = 2.33, v_tdma = -0.0\n",
      "Gain = 1.000730840425976\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.89477327]], y_hat_TDMA = [[0.00231942]]\n",
      "Evaluation: v_csma = 2.17, v_tdma = -0.01\n",
      "No update. Forest is already full.\n",
      "Gain = 1.0026101556077494\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.59026791]], y_hat_TDMA = [[0.00413565]]\n",
      "Evaluation: v_csma = 1.86, v_tdma = -0.0\n",
      "Gain = 1.0019588813495652\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.99719817]], y_hat_TDMA = [[0.00198837]]\n",
      "Evaluation: v_csma = 2.27, v_tdma = -0.01\n",
      "Gain = 1.0024259163333844\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.98995862]], y_hat_TDMA = [[0.00196852]]\n",
      "Evaluation: v_csma = 2.26, v_tdma = -0.01\n",
      "Gain = 1.0023203258909332\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.68545326]], y_hat_TDMA = [[0.00196852]]\n",
      "Evaluation: v_csma = 1.96, v_tdma = -0.0\n",
      "Gain = 1.0025470326598893\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[5.05670729]], y_hat_TDMA = [[0.00332679]]\n",
      "Evaluation: v_csma = 2.33, v_tdma = -0.0\n",
      "Gain = 1.0014802392854685\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[5.00352688]], y_hat_TDMA = [[0.00534095]]\n",
      "Evaluation: v_csma = 2.28, v_tdma = -0.0\n",
      "Gain = 1.0005985801390498\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.68823104]], y_hat_TDMA = [[0.00198214]]\n",
      "Evaluation: v_csma = 1.96, v_tdma = -0.0\n",
      "Gain = 1.0022870005872864\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[5.05670729]], y_hat_TDMA = [[0.00332679]]\n",
      "Evaluation: v_csma = 2.33, v_tdma = -0.0\n",
      "Gain = 1.0012807171561162\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.98497458]], y_hat_TDMA = [[0.00330601]]\n",
      "Evaluation: v_csma = 2.26, v_tdma = -0.0\n",
      "Gain = 1.0012640742601877\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.98995862]], y_hat_TDMA = [[0.00212733]]\n",
      "Evaluation: v_csma = 2.26, v_tdma = -0.0\n",
      "No update. Forest is already full.\n",
      "Gain = 1.0016930334332184\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[5.05670729]], y_hat_TDMA = [[0.0017868]]\n",
      "Evaluation: v_csma = 2.33, v_tdma = -0.0\n",
      "Gain = 1.0017011550014674\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.96152194]], y_hat_TDMA = [[0.00602096]]\n",
      "Evaluation: v_csma = 2.23, v_tdma = 0.0\n",
      "Gain = 0.9998848391008285\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.84183346]], y_hat_TDMA = [[0.00190704]]\n",
      "Evaluation: v_csma = 2.11, v_tdma = -0.0\n",
      "Gain = 1.0017323671448513\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[5.00352688]], y_hat_TDMA = [[0.00534095]]\n",
      "Evaluation: v_csma = 2.28, v_tdma = -0.0\n",
      "Gain = 1.0000959113655448\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[5.05670729]], y_hat_TDMA = [[0.00649725]]\n",
      "Evaluation: v_csma = 2.33, v_tdma = 0.0\n",
      "Gain = 0.9996175340498441\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[5.05670729]], y_hat_TDMA = [[0.0091429]]\n",
      "Evaluation: v_csma = 2.33, v_tdma = 0.0\n",
      "Gain = 0.9985578493391264\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.98995862]], y_hat_TDMA = [[0.00699069]]\n",
      "Evaluation: v_csma = 2.26, v_tdma = 0.0\n",
      "Gain = 0.9994930316996713\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.68545326]], y_hat_TDMA = [[0.00227518]]\n",
      "Evaluation: v_csma = 1.96, v_tdma = -0.0\n",
      "Gain = 1.0017308265248723\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[5.05670729]], y_hat_TDMA = [[0.0017868]]\n",
      "Evaluation: v_csma = 2.33, v_tdma = -0.0\n",
      "Gain = 1.0015814067142967\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.99719817]], y_hat_TDMA = [[0.00197785]]\n",
      "Evaluation: v_csma = 2.27, v_tdma = -0.0\n",
      "No update. Forest is already full.\n",
      "Gain = 1.00146177298747\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.98995862]], y_hat_TDMA = [[0.00204579]]\n",
      "Evaluation: v_csma = 2.26, v_tdma = -0.0\n",
      "Gain = 1.0013646061133417\n",
      "---\n",
      "Prot: 1, y = 0.01666649989783764\n",
      "y_hat_CSMA = [[4.98995862]], y_hat_TDMA = [[0.00926082]]\n",
      "Evaluation: v_csma = 2.26, v_tdma = 0.0\n",
      "Gain = 0.9978992999494246\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.68823104]], y_hat_TDMA = [[0.00528061]]\n",
      "Evaluation: v_csma = 1.96, v_tdma = 0.0\n",
      "Gain = 0.9996252419043569\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.68545326]], y_hat_TDMA = [[0.00277605]]\n",
      "Evaluation: v_csma = 1.96, v_tdma = -0.0\n",
      "Gain = 1.0008583489422624\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.68545326]], y_hat_TDMA = [[0.00180662]]\n",
      "Evaluation: v_csma = 1.96, v_tdma = -0.0\n",
      "Gain = 1.0012856682734894\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.98995862]], y_hat_TDMA = [[0.00174514]]\n",
      "Evaluation: v_csma = 2.26, v_tdma = -0.0\n",
      "Gain = 1.0010828478336333\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.68545326]], y_hat_TDMA = [[0.00223014]]\n",
      "Evaluation: v_csma = 1.96, v_tdma = -0.0\n",
      "Gain = 1.0009533917269102\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.98995862]], y_hat_TDMA = [[0.00220769]]\n",
      "Evaluation: v_csma = 2.26, v_tdma = -0.0\n",
      "Gain = 1.0007932720194999\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[5.00352688]], y_hat_TDMA = [[0.00520683]]\n",
      "Evaluation: v_csma = 2.28, v_tdma = 0.0\n",
      "Gain = 0.9994975980349502\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.90201283]], y_hat_TDMA = [[0.00413622]]\n",
      "Evaluation: v_csma = 2.18, v_tdma = 0.0\n",
      "No. of new estimators = 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gain = 0.9999680503515039\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[4.95819632]], y_hat_TDMA = [[0.00156322]]\n",
      "Evaluation: v_csma = 2.23, v_tdma = -0.0\n",
      "Gain = 1.0006285379864346\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[5.05670729]], y_hat_TDMA = [[0.00124478]]\n",
      "Evaluation: v_csma = 2.33, v_tdma = -0.0\n",
      "Gain = 1.0007017153481934\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00025574]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.0034784707471816\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00036759]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.0031562684290403\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00024617]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.0031594222740223\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00025574]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.0029887626746694\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00029049]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.0027932609205814\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00024668]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.0027116681947787\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00038195]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.0023967551981046\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00025574]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "No update. Forest is already full.\n",
      "Gain = 1.0024442403252627\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00040728]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.002121134887663\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00030495]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.0021507390746687\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00031931]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.002024158014654\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00024617]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.0020199151958022\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00036759]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.001757952169578\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00025574]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.0018183333418813\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00031049]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.0016548385366597\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00026617]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.001630848715833\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00025574]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.0015631323121625\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00025625]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "No update. Forest is already full.\n",
      "Gain = 1.0014842939107744\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00038195]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.0012434381139521\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00024668]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.0013605957951899\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00024617]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.0012932477912104\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00024617]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.00122858540165\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00036759]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.0010061888651334\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00026617]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.0010903321705378\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00024668]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.0010616482940038\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00024617]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.0010092476650838\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00027397]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.0009219347452583\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00026617]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "No update. Forest is already full.\n",
      "Gain = 1.0008861740267936\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.0002701]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.0008366472512937\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00036759]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.0006655802142281\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00024617]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.0007932684699508\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00025574]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.0007409165608014\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00026617]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.0006900447006404\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00025574]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.0006693684977295\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00029049]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.0005898364524883\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00024617]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.0006190967358704\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00029049]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.0005293897930705\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00025574]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "No update. Forest is already full.\n",
      "Gain = 1.0005489839237716\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00024617]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.0005342232132346\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00026053]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.0004884679462915\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00024617]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.0004830886552583\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00024617]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.0004589342224954\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00024668]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.0004353057255906\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00029049]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.0003554701190849\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00024668]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.0003957669333567\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00024617]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.000376660372469\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00024617]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.0003578273538456\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00030495]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "No update. Forest is already full.\n",
      "Gain = 1.000262015010554\n",
      "---\n",
      "Prot: 1, y = 0.01666649989783764\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00740985]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.01\n",
      "Gain = 0.9896670184206556\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00024668]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9996799143378938\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00024617]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9996966004067791\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00024617]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9997117703864402\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00024617]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9997261818671181\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00029049]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9996811206677558\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00026053]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9997367726340931\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00024617]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9997689781086698\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00025574]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9997678407175845\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00024617]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "No. of new estimators = 10\n",
      "Gain = 0.9997921371673572\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00021772]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9997815704319964\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00027002]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9997231565141682\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00020336]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9998253781909696\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00028669]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9997236349032838\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.0002454]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9997921868004204\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00035262]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9996604361450692\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00031624]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9997256450744756\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00031624]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9997393628207518\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00020902]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9998945359950444\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00021772]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "No update. Forest is already full.\n",
      "Gain = 0.9998882750881876\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00028669]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9998024310619221\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00021772]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.999903739780682\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00030184]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9997970346527729\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00020336]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9999377451652907\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00030184]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9998102956618699\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00020336]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9999503431239326\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00021945]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9999314899364381\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00028669]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9998457770927767\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00038517]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9997229259929816\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00030184]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No update. Forest is already full.\n",
      "Gain = 0.9998472540714699\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00038113]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9997497749396931\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00020336]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.999997964866068\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.0002978]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9998728623275422\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.0002454]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9999486827705509\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00038517]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9997659527445664\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00038113]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.999783013057272\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00028669]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9999190666996307\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00020902]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.0000260777436099\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00049806]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9996415959178055\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00028669]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "No update. Forest is already full.\n",
      "Gain = 0.9999397296815784\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00032307]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9998945124608396\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00028669]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9999480175744576\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00028669]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9999506166957346\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00020902]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.0000560502399087\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00035262]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.999862875675923\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00024502]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.000012376754225\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00030751]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9999289228612495\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00033061]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9999018535417317\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00030346]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9999427419910345\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00628992]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.01\n",
      "No update. Forest is already full.\n",
      "Gain = 0.9920093194021741\n",
      "---\n",
      "Prot: 1, y = 0.01666649989783764\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00041068]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9990401094151248\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00024502]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.999307722365029\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00025583]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9993280066678883\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00021945]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9994098370711539\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00035262]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9992627991977272\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.0002454]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9994418005531711\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00020336]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9995254512613492\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00023974]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9995009479616217\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00038517]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.999333094676907\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00020902]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "No. of new estimators = 10\n",
      "Gain = 0.9995999665671786\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00047265]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9992541788759688\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00050374]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9992502640344976\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00047265]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9993289567304454\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00050472]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9993199997349321\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00021533]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9997376491437879\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00060872]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9992292451843369\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00050374]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9994069582930974\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00020663]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9998304906198316\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00021533]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9998274319817354\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00040929]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "No update. Forest is already full.\n",
      "Gain = 0.9995789185435865\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00060872]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9993355929532074\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00050472]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9995066854122062\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00047265]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9995738603005871\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00049905]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9995601681257432\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00049905]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9995821597194561\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.0002344]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9999539004443014\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00037586]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9997686711542917\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00047265]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9996519223133682\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00050374]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.999628120300027\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00021533]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "No update. Forest is already full.\n",
      "Gain = 1.0000290604193098\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00040929]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9997704655592823\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00021533]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.0000390841203803\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00049905]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9996609905179352\n",
      "---\n",
      "Prot: 1, y = 0.01666649989783764\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00549151]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.01\n",
      "Gain = 0.991896526949442\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00030594]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.999176234588377\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00047265]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.998996413884043\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00041496]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9991230815882138\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00056496]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9989680736281559\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00048607]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9991242547425913\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00066662]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "No. of new estimators = 10\n",
      "Gain = 0.9989286808528308\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00073007]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9989087498253431\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.0005969]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9991398663257118\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00075893]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9989680608218166\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00064674]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9991683903548368\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00075893]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9990612382629839\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00029167]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9997276345607399\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00076362]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9991155878839394\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00033862]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9997232278182427\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00033862]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9997370664273306\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.0005969]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "No update. Forest is already full.\n",
      "Gain = 0.9994078127029317\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00043584]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9996509356963238\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00024182]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9999256009197631\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00025529]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9999114700181504\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00025529]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9999158965172429\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00051917]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9995702661606126\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00540837]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.993110116844608\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00025523]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.000286152710313\n",
      "---\n",
      "Prot: 1, y = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00075893]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9996040879368248\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00075893]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9996238835399834\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00075893]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "No update. Forest is already full.\n",
      "Gain = 0.9996426893629843\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00025523]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.000328312032808\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00067555]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9997546838405253\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00068023]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9997607429106409\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00043584]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.0000966937717848\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00033862]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.0002207458576893\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00075893]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9996524959741627\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00068028]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9997741388157336\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00025523]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.0003489213726406\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00076362]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9996575114281776\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00068028]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "No update. Forest is already full.\n",
      "Gain = 0.9997851102349059\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00031084]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.0002856244662361\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00075893]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9996773058595698\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00022751]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.000397952328083\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00025523]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.0003413000881598\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00076362]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9996502712079209\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00080873]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9996079549410781\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00081341]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "Gain = 0.9996213504561658\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00033862]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.000269711706163\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00024182]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.0003845513546168\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00068028]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = 0.0\n",
      "No update. Forest is already full.\n",
      "Gain = 0.999784053602761\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[3.44354982]], y_hat_TDMA = [[0.00024182]]\n",
      "Evaluation: v_csma = 0.72, v_tdma = -0.0\n",
      "Gain = 1.000376121106748\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "err_csma = []\n",
    "err_tdma = []\n",
    "\n",
    "y_csma = []\n",
    "y_tdma = []\n",
    "\n",
    "for t in range(len(test_keys)):\n",
    "    prot, gain, y_hat_csma, y_hat_tdma = somac.decision(test_data[t])\n",
    "    y = test_data[t][\"metrics\"][0, 1]\n",
    "    prot = test_data[t][\"prot\"]\n",
    "    \n",
    "    if prot == 0:\n",
    "        err_csma.append(np.abs(float(y_hat_csma - y)))\n",
    "        y_csma.append(float(y))\n",
    "    else:\n",
    "        err_tdma.append(np.abs(float(y_hat_tdma - y)))\n",
    "        y_tdma.append(float(y))\n",
    "\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb2aaca6a20>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(0, np.mean(err_csma) / np.mean(y_csma))\n",
    "plt.bar(1, np.mean(err_tdma) / np.mean(y_tdma))\n",
    "plt.ylim([0, 1])\n",
    "plt.legend([\"CSMA\", \"TDMA\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
