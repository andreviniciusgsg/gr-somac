{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from RandomForest import RandomForest\n",
    "from SOMAC import SOMAC\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size = 78, Test set size = 52\n"
     ]
    }
   ],
   "source": [
    "filename = \"/home/andre/UFMG/SOMAC-ML/data/18092018/somac/RF-noweight/backlog_file.npy\"\n",
    "\n",
    "data = np.load(filename, encoding = \"latin1\").item()\n",
    "\n",
    "tkeys = np.array(list(data.keys()))\n",
    "\n",
    "train_keys = []\n",
    "test_keys = []\n",
    "\n",
    "for t in tkeys[:130]:\n",
    "    if np.random.rand() < 0.6:\n",
    "        train_keys.append(t)\n",
    "    else:\n",
    "        test_keys.append(t)\n",
    "        \n",
    "train = {}\n",
    "for i, t in zip(range(len(train_keys)), train_keys):\n",
    "    train[i] = data[t]\n",
    "train_file = \"./_tmp/train_file.npy\"\n",
    "np.save(train_file, train)\n",
    "\n",
    "test = {}\n",
    "for i, t in zip(range(len(test_keys)), test_keys):\n",
    "    test[i] = data[t]\n",
    "test_file = \"./_tmp/test_file.npy\"\n",
    "np.save(test_file, test)\n",
    "\n",
    "print(\"Train set size = {}, Test set size = {}\".format(len(train_keys), len(test_keys)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.load(test_file, encoding = \"latin1\").item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# somac = SOMAC(reg_csma = RandomForest(), reg_tdma = EsembleNNet())\n",
    "# EsembleNNet(n_new_estimators = 10, n_neurons = 3)\n",
    "somac = SOMAC(reg_csma = RandomForest(n_estimators = 100, max_depth = 5, max_features = \"log2\", n_new_estimators = 10),\n",
    "              reg_tdma = RandomForest(n_estimators = 100, max_depth = 5, max_features = \"log2\", n_new_estimators = 10))\n",
    "somac.train(train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prot: 0, y = 15.0005745254457\n",
      "y_hat_CSMA = [[3.98715722]], y_hat_TDMA = [[5.29501196]]\n",
      "Evaluation: v_csma = 4.54, v_tdma = 5.3\n",
      "Gain = 0.1431233661804731\n",
      "---\n",
      "Prot: 0, y = 16.566666301339865\n",
      "y_hat_CSMA = [[8.04228694]], y_hat_TDMA = [[5.67291027]]\n",
      "Evaluation: v_csma = 8.99, v_tdma = 5.67\n",
      "Gain = 0.36904240035994723\n",
      "---\n",
      "Prot: 0, y = 20.36724125407636\n",
      "y_hat_CSMA = [[12.99554384]], y_hat_TDMA = [[6.8039411]]\n",
      "Evaluation: v_csma = 14.27, v_tdma = 6.8\n",
      "Gain = 0.5230429028935613\n",
      "---\n",
      "Prot: 0, y = 17.5942526422441\n",
      "y_hat_CSMA = [[12.64730247]], y_hat_TDMA = [[6.82273476]]\n",
      "Evaluation: v_csma = 14.1, v_tdma = 6.82\n",
      "Gain = 0.5161497361158278\n",
      "---\n",
      "Prot: 0, y = 21.380459245294333\n",
      "y_hat_CSMA = [[12.95984154]], y_hat_TDMA = [[5.58697229]]\n",
      "Evaluation: v_csma = 14.76, v_tdma = 5.59\n",
      "Gain = 0.621523769509998\n",
      "---\n",
      "Prot: 0, y = 20.266667064279318\n",
      "y_hat_CSMA = [[11.76025478]], y_hat_TDMA = [[6.17777421]]\n",
      "Evaluation: v_csma = 13.9, v_tdma = 6.18\n",
      "Gain = 0.5554730777095536\n",
      "---\n",
      "Prot: 0, y = 24.58333295211196\n",
      "y_hat_CSMA = [[20.86849307]], y_hat_TDMA = [[8.35197903]]\n",
      "Evaluation: v_csma = 23.08, v_tdma = 8.35\n",
      "Gain = 0.638199403301766\n",
      "---\n",
      "Prot: 0, y = 26.872988399118185\n",
      "y_hat_CSMA = [[23.91764437]], y_hat_TDMA = [[7.4585786]]\n",
      "Evaluation: v_csma = 26.17, v_tdma = 7.46\n",
      "Gain = 0.715000789554372\n",
      "---\n",
      "Prot: 0, y = 29.13160991668701\n",
      "y_hat_CSMA = [[27.73812437]], y_hat_TDMA = [[16.60259476]]\n",
      "Evaluation: v_csma = 29.95, v_tdma = 16.6\n",
      "Gain = 0.4456223292579941\n",
      "---\n",
      "Prot: 0, y = 25.94425320625305\n",
      "y_hat_CSMA = [[28.73785033]], y_hat_TDMA = [[16.71616813]]\n",
      "Evaluation: v_csma = 30.7, v_tdma = 16.72\n",
      "No. of new estimators = 9\n",
      "Gain = 0.4554586098734553\n",
      "---\n",
      "Prot: 0, y = 28.396552324295044\n",
      "y_hat_CSMA = [[27.83741449]], y_hat_TDMA = [[16.68223096]]\n",
      "Evaluation: v_csma = 29.37, v_tdma = 16.68\n",
      "Gain = 0.4319550978463188\n",
      "---\n",
      "Prot: 0, y = 29.064367711544037\n",
      "y_hat_CSMA = [[27.76831656]], y_hat_TDMA = [[16.68223096]]\n",
      "Evaluation: v_csma = 29.29, v_tdma = 16.68\n",
      "Gain = 0.4303874890391117\n",
      "---\n",
      "Prot: 0, y = 30.116666492074728\n",
      "y_hat_CSMA = [[29.09689841]], y_hat_TDMA = [[17.7892765]]\n",
      "Evaluation: v_csma = 30.59, v_tdma = 17.79\n",
      "Gain = 0.41847271844157363\n",
      "---\n",
      "Prot: 0, y = 27.679884925484657\n",
      "y_hat_CSMA = [[29.05262823]], y_hat_TDMA = [[18.11377983]]\n",
      "Evaluation: v_csma = 30.4, v_tdma = 18.11\n",
      "Gain = 0.4042111044019249\n",
      "---\n",
      "Prot: 0, y = 31.652299407869577\n",
      "y_hat_CSMA = [[28.9062179]], y_hat_TDMA = [[18.22858374]]\n",
      "Evaluation: v_csma = 30.33, v_tdma = 18.23\n",
      "Gain = 0.39891999517095683\n",
      "---\n",
      "Prot: 0, y = 31.31724101305008\n",
      "y_hat_CSMA = [[28.19739228]], y_hat_TDMA = [[20.60055059]]\n",
      "Evaluation: v_csma = 29.7, v_tdma = 20.6\n",
      "Gain = 0.3064384476777493\n",
      "---\n",
      "Prot: 0, y = 30.066666696220636\n",
      "y_hat_CSMA = [[28.25121597]], y_hat_TDMA = [[18.24338681]]\n",
      "Evaluation: v_csma = 29.77, v_tdma = 18.24\n",
      "Gain = 0.3872273993775338\n",
      "---\n",
      "Prot: 0, y = 31.183333594352007\n",
      "y_hat_CSMA = [[28.3161179]], y_hat_TDMA = [[18.24338681]]\n",
      "Evaluation: v_csma = 29.9, v_tdma = 18.24\n",
      "Gain = 0.3899368007486604\n",
      "---\n",
      "Prot: 0, y = 31.178735055029392\n",
      "y_hat_CSMA = [[28.26043294]], y_hat_TDMA = [[18.09851882]]\n",
      "Evaluation: v_csma = 29.92, v_tdma = 18.1\n",
      "Gain = 0.39500018632415446\n",
      "---\n",
      "Prot: 0, y = 29.783332707360387\n",
      "y_hat_CSMA = [[27.97752187]], y_hat_TDMA = [[20.68757901]]\n",
      "Evaluation: v_csma = 29.64, v_tdma = 20.69\n",
      "No. of new estimators = 2\n",
      "Gain = 0.30202868833569857\n",
      "---\n",
      "Prot: 0, y = 25.627011876553297\n",
      "y_hat_CSMA = [[29.07154235]], y_hat_TDMA = [[19.81641581]]\n",
      "Evaluation: v_csma = 30.12, v_tdma = 19.82\n",
      "Gain = 0.3419736730128574\n",
      "---\n",
      "Prot: 0, y = 28.30000071413815\n",
      "y_hat_CSMA = [[28.71149853]], y_hat_TDMA = [[19.97394769]]\n",
      "Evaluation: v_csma = 29.68, v_tdma = 19.97\n",
      "Gain = 0.3270717741440337\n",
      "---\n",
      "Prot: 0, y = 31.1844822447747\n",
      "y_hat_CSMA = [[28.79649432]], y_hat_TDMA = [[22.56715474]]\n",
      "Evaluation: v_csma = 29.84, v_tdma = 22.57\n",
      "Gain = 0.24367756592461964\n",
      "---\n",
      "Prot: 0, y = 29.70000010728836\n",
      "y_hat_CSMA = [[29.20218026]], y_hat_TDMA = [[24.23030343]]\n",
      "Evaluation: v_csma = 30.22, v_tdma = 24.23\n",
      "Gain = 0.19811045329909194\n",
      "---\n",
      "Prot: 0, y = 26.38333421945572\n",
      "y_hat_CSMA = [[28.59282239]], y_hat_TDMA = [[21.45477037]]\n",
      "Evaluation: v_csma = 29.45, v_tdma = 21.45\n",
      "Gain = 0.27138455056710253\n",
      "---\n",
      "Prot: 0, y = 0.7333329729735851\n",
      "y_hat_CSMA = [[3.46403084]], y_hat_TDMA = [[5.24242774]]\n",
      "Evaluation: v_csma = 4.14, v_tdma = 5.24\n",
      "Gain = 0.2106697377247963\n",
      "---\n",
      "Prot: 0, y = 0.43333299830555916\n",
      "y_hat_CSMA = [[3.0126169]], y_hat_TDMA = [[5.43101849]]\n",
      "Evaluation: v_csma = 3.52, v_tdma = 5.43\n",
      "Gain = 0.3511458899012827\n",
      "---\n",
      "Prot: 1, y = 2.635631963610649\n",
      "y_hat_CSMA = [[8.16745121]], y_hat_TDMA = [[5.60154899]]\n",
      "Evaluation: v_csma = 8.68, v_tdma = 5.45\n",
      "Gain = 0.3716507970865894\n",
      "---\n",
      "Prot: 0, y = 8.93333287537098\n",
      "y_hat_CSMA = [[24.01965132]], y_hat_TDMA = [[8.42723095]]\n",
      "Evaluation: v_csma = 23.75, v_tdma = 8.28\n",
      "Gain = 0.6514265931259506\n",
      "---\n",
      "Prot: 0, y = 0.5\n",
      "y_hat_CSMA = [[11.97438893]], y_hat_TDMA = [[5.68754823]]\n",
      "Evaluation: v_csma = 11.15, v_tdma = 5.54\n",
      "Gain = 0.5030020269916448\n",
      "---\n",
      "Prot: 0, y = 0.4833335131406784\n",
      "y_hat_CSMA = [[5.4608972]], y_hat_TDMA = [[4.55031268]]\n",
      "Evaluation: v_csma = 4.42, v_tdma = 4.4\n",
      "No. of new estimators = 10\n",
      "Gain = 0.0050984765761165705\n",
      "---\n",
      "Prot: 1, y = 13.112069487571716\n",
      "y_hat_CSMA = [[27.36761273]], y_hat_TDMA = [[16.88722029]]\n",
      "Evaluation: v_csma = 26.51, v_tdma = 16.56\n",
      "Gain = 0.37553510565111514\n",
      "---\n",
      "Prot: 1, y = 19.494827151298523\n",
      "y_hat_CSMA = [[28.29437656]], y_hat_TDMA = [[18.79618467]]\n",
      "Evaluation: v_csma = 27.44, v_tdma = 18.52\n",
      "Gain = 0.32518683989311975\n",
      "---\n",
      "Prot: 1, y = 19.318965196609497\n",
      "y_hat_CSMA = [[28.65836849]], y_hat_TDMA = [[18.58058843]]\n",
      "Evaluation: v_csma = 27.81, v_tdma = 18.35\n",
      "Gain = 0.33994626857566496\n",
      "---\n",
      "Prot: 1, y = 20.87643700838089\n",
      "y_hat_CSMA = [[27.73102948]], y_hat_TDMA = [[21.05053431]]\n",
      "Evaluation: v_csma = 26.88, v_tdma = 20.83\n",
      "Gain = 0.22518111129745977\n",
      "---\n",
      "Prot: 1, y = 21.707471132278442\n",
      "y_hat_CSMA = [[27.74199576]], y_hat_TDMA = [[21.12301309]]\n",
      "Evaluation: v_csma = 26.89, v_tdma = 20.94\n",
      "Gain = 0.22129712083164932\n",
      "---\n",
      "Prot: 1, y = 24.58563244342804\n",
      "y_hat_CSMA = [[28.16865749]], y_hat_TDMA = [[22.83045294]]\n",
      "Evaluation: v_csma = 27.32, v_tdma = 22.74\n",
      "Gain = 0.1674032003640728\n",
      "---\n",
      "Prot: 1, y = 25.23793053627014\n",
      "y_hat_CSMA = [[28.5969091]], y_hat_TDMA = [[23.13292455]]\n",
      "Evaluation: v_csma = 27.74, v_tdma = 23.16\n",
      "Gain = 0.1654019620712729\n",
      "---\n",
      "Prot: 1, y = 24.466665983200073\n",
      "y_hat_CSMA = [[28.25896971]], y_hat_TDMA = [[23.76393066]]\n",
      "Evaluation: v_csma = 27.41, v_tdma = 23.82\n",
      "Gain = 0.13084541129293004\n",
      "---\n",
      "Prot: 1, y = 24.88333361595869\n",
      "y_hat_CSMA = [[28.5969091]], y_hat_TDMA = [[23.27863802]]\n",
      "Evaluation: v_csma = 27.74, v_tdma = 23.41\n",
      "No. of new estimators = 4\n",
      "Gain = 0.15613349777233806\n",
      "---\n",
      "Prot: 1, y = 24.818964809179306\n",
      "y_hat_CSMA = [[28.61821863]], y_hat_TDMA = [[23.92139269]]\n",
      "Evaluation: v_csma = 27.77, v_tdma = 24.06\n",
      "Gain = 0.13349061358756703\n",
      "---\n",
      "Prot: 1, y = 25.04310319572687\n",
      "y_hat_CSMA = [[29.35302795]], y_hat_TDMA = [[24.10226907]]\n",
      "Evaluation: v_csma = 28.5, v_tdma = 24.28\n",
      "Gain = 0.14807594935408563\n",
      "---\n",
      "Prot: 1, y = 24.6149424277246\n",
      "y_hat_CSMA = [[26.40960143]], y_hat_TDMA = [[14.7982247]]\n",
      "Evaluation: v_csma = 25.56, v_tdma = 15.46\n",
      "Gain = 0.3951526886238035\n",
      "---\n",
      "Prot: 1, y = 11.533332865685225\n",
      "y_hat_CSMA = [[2.3186904]], y_hat_TDMA = [[2.63415813]]\n",
      "Evaluation: v_csma = 1.47, v_tdma = 3.71\n",
      "Gain = 0.6044106519687852\n",
      "---\n",
      "Prot: 1, y = 0.6833335012197495\n",
      "y_hat_CSMA = [[2.21131785]], y_hat_TDMA = [[2.58516337]]\n",
      "Evaluation: v_csma = 1.36, v_tdma = 3.51\n",
      "Gain = 0.6127264419757558\n",
      "---\n",
      "Prot: 1, y = 0.33333350718021393\n",
      "y_hat_CSMA = [[2.25075884]], y_hat_TDMA = [[1.46068312]]\n",
      "Evaluation: v_csma = 1.4, v_tdma = 2.28\n",
      "Gain = 0.38713869138263146\n",
      "---\n",
      "Prot: 1, y = 0.20000000298023224\n",
      "y_hat_CSMA = [[2.57153213]], y_hat_TDMA = [[1.04226831]]\n",
      "Evaluation: v_csma = 1.72, v_tdma = 1.78\n",
      "Gain = 0.034183895575098266\n",
      "---\n",
      "Prot: 1, y = 0.15000000223517418\n",
      "y_hat_CSMA = [[2.87257643]], y_hat_TDMA = [[1.03462761]]\n",
      "Evaluation: v_csma = 2.02, v_tdma = 1.69\n",
      "Gain = 0.1628534742868237\n",
      "---\n",
      "Prot: 1, y = 0.20000000298023224\n",
      "y_hat_CSMA = [[2.74904156]], y_hat_TDMA = [[0.98295122]]\n",
      "Evaluation: v_csma = 1.9, v_tdma = 1.57\n",
      "Gain = 0.1735181126586053\n",
      "---\n",
      "Prot: 1, y = 0.18333350121974945\n",
      "y_hat_CSMA = [[2.25908755]], y_hat_TDMA = [[0.91298033]]\n",
      "Evaluation: v_csma = 1.41, v_tdma = 1.43\n",
      "No. of new estimators = 10\n",
      "Gain = 0.017619194327042488\n",
      "---\n",
      "Prot: 1, y = 0.11666649952530861\n",
      "y_hat_CSMA = [[2.20755878]], y_hat_TDMA = [[0.36186688]]\n",
      "Evaluation: v_csma = 1.35, v_tdma = 0.76\n",
      "Gain = 0.43750774882848603\n",
      "---\n",
      "Prot: 1, y = 0.0\n",
      "y_hat_CSMA = [[2.57153213]], y_hat_TDMA = [[0.38781422]]\n",
      "Evaluation: v_csma = 1.72, v_tdma = 0.75\n",
      "Gain = 0.5644443540295314\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "err_csma = []\n",
    "err_tdma = []\n",
    "\n",
    "y_csma = []\n",
    "y_tdma = []\n",
    "\n",
    "for t in range(len(test_keys)):\n",
    "    prot, gain, y_hat_csma, y_hat_tdma = somac.decision(test_data[t])\n",
    "    y = test_data[t][\"metrics\"][0, 1]\n",
    "    prot = test_data[t][\"prot\"]\n",
    "    \n",
    "    if prot == 0:\n",
    "        err_csma.append(np.abs(float(y_hat_csma - y)))\n",
    "        y_csma.append(float(y))\n",
    "    else:\n",
    "        err_tdma.append(np.abs(float(y_hat_tdma - y)))\n",
    "        y_tdma.append(float(y))\n",
    "\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb2ad084668>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(0, np.mean(err_csma) / np.mean(y_csma))\n",
    "plt.bar(1, np.mean(err_tdma) / np.mean(y_tdma))\n",
    "plt.ylim([0, 1])\n",
    "plt.legend([\"CSMA\", \"TDMA\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
